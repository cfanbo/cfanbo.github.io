---
title: 数据中心TCP优化：同时满足低时延和高吞吐量
author: admin
type: post
date: 2011-06-12T10:44:52+00:00
url: /archives/9750
IM_data:
 - 'a:7:{s:57:"http://s9.sinaimg.cn/middle/5374d6e3ta579d882e8e8&690";s:57:"http://blog.haohtml.com/wp-content/uploads/2011/06/e3c1b.";s:57:"http://s4.sinaimg.cn/middle/5374d6e3ta57b0c8bf3a3&690";s:57:"http://blog.haohtml.com/wp-content/uploads/2011/06/4ce66.";s:58:"http://s12.sinaimg.cn/middle/5374d6e3ta57b3a34833b&690";s:57:"http://blog.haohtml.com/wp-content/uploads/2011/06/6106f.";s:57:"http://s9.sinaimg.cn/middle/5374d6e3ta57ba9de10d8&690";s:57:"http://blog.haohtml.com/wp-content/uploads/2011/06/c62c3.";s:58:"http://s14.sinaimg.cn/middle/5374d6e3ta57ca2034ecd&690";s:57:"http://blog.haohtml.com/wp-content/uploads/2011/06/56f41.";s:58:"http://s14.sinaimg.cn/middle/5374d6e3ta57ca6a9768d&690";s:57:"http://blog.haohtml.com/wp-content/uploads/2011/06/0e5d1.";s:58:"http://s16.sinaimg.cn/middle/5374d6e3ta57caa41b25f&690";s:57:"http://blog.haohtml.com/wp-content/uploads/2011/06/13ac0.";}'
IM_contentdowned:
 - 1
categories:
 - 服务器

---
大的数据中心有成千上万台服务器，服务器之间大都用TCP来协作并传输数据，最终为用户提供服务。那数据中心的TCP工作得如何呢？ 斯坦福大学和微软的两人对Bing服务的6000多台服务器集群在TCP方面的数据进行研究，用的数据是一个月的日志，包括应用、套接字级别和包级别的日志，压缩完后大概是150T的数据。老外真是牛！

**一、发现的问题**
1、突发的丢包现象
2、部分包传输时延大，90%的传输RTT值小于1毫秒，10%的RTT值在1到15毫秒之间

**二、可能的原因**
交换机是是先存储后转发数据包的，在一个端口上缓冲的数据包太多时，会有两种结果，一是交换机会丢掉新过来的包，二是已经缓冲的包的转发时延变大。这就是造成上面问题的原因。

下面是两种场景，第一种是如下图：
[![](http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_worker1-300x198.png)][1]
多台工作机器把数据发给一台负责聚合的机器，这个有时会造成聚合机器所连接的交换机端口上缓冲太多的数据包，因缓冲区不多了而丢弃新收到的包。这些有些工作机器会出现超时重发。

另一种场景如下图：

[![](http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_send_receiver2.png)][2]

两种机器同时给另一台机器发数据，其中一台发送的数据量很大，这样使得接收者上连的交换机端口缓冲区缓冲了大量数据包，使得另一个发送者发送的少量数据包产生比较大延迟。

**三、数据中心内部传输的需求**

. 要能适应高突发性流量，上面第一种场景中负责聚合机器上连端口流量经常会出现突增
. 低时延传输，象查询和任务转发必须很快传到各台机器上，不然多台机器协作完成的任务整体时间就无法满足用户的需求了
. 高吞吐量传输，需要满足大文件传输，持续数据更新等吞吐量要求

这些需求需要同时满足，但是它们之间存在冲突：

[![](http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_buffers.png)][3]

表面上看，要实现高吞吐量传输和允许端口流量突增，需要加大缓冲区大小，这样就会增大传输时延；相反，要实现低时延传输，要求缓冲空间小。

所以，目标是很少占用缓冲区的情况下实现高吞吐量传输。怎么样才能作到呢？

解决方法是采用数据中心TCP算法。

**四、数据中心TCP算法介绍**

交换机上的改动：
当一个端口缓冲的数据包超过某个设定的个数时，将给后续进来的包加上ECN(显式地拥塞通知)。数据包接受者会在回包给发送者时附上这些信息，这部分在现有的TCP/IP中代码中已经实现

发送者：
发送者根椐收到ACK包中带ECN标志的比例，来确定发送窗口的减少程度。比例越高，窗口减少越多。而不是传统的出现拥塞就减半的策略。这样就能保证吞吐量的需求。具本算法见后面的参考链接部分。

通过这些调整，将使得发送者适应缓冲区的占用情况，动态调整自己的发送速度，而不是等到数据包丢弃时才有所动作。

**五、效果**

[![](http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_queue.png)][4][
][5]

该图中，用的是Broadcom千兆交换机，从两个不同的千兆端口，往另一个端口发送数据，这两个数据流持续时间长。对DCTCP(数据中心TCP)，在交换机设置加ECN标志的阀值是20个包(30KB)。对于TCP和DCTCP在实验中都吞吐量都能用满千兆。

从图中明显看出，传统的TCP传输时交换机缓冲区占用比DCTCP大，且波动量很大。这也意味着时延要高一些。

[![](http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_query-flows-2.png)][5][
][6]

短数据流时时延很低

[![](http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_query-flows-1.png)][6]

保证了大数据流的高吞吐量

[![](http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_query-flows-0.png)][7]

适应查询时的端口流量突增的情况

**六、参考链接**

[Analysis of DCTCP: Stability, Convergence, and Fairness](http://www.stanford.edu/~alizade/Site/DCTCP_files/dctcp_analysis-full.pdf) [Data Center TCP (DCTCP)](http://www.stanford.edu/~alizade/Site/DCTCP_files/dctcp-final.pdf) [Data Center TCP (DCTCP)](http://www.stanford.edu/~alizade/Site/DCTCP_files/DCTCP-talk.pptx) [In Defense of TCP](http://www.stanford.edu/~alizade/Site/DCTCP_files/train-wrecks-BalajiPrabhakar_1.ppt)

针对linux最新内核的patch: [dctcp-2.6.38.3-rev1_0_0.tar.gz](http://www.stanford.edu/~alizade/Site/DCTCP_files/dctcp-2.6.38.3-rev1_0_0.tar.gz)

摘自:

 [1]: http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_worker1.png
 [2]: http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_send_receiver2.png
 [3]: http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_buffers.png
 [4]: http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_queue.png
 [5]: http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_query-flows-2.png
 [6]: http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_query-flows-1.png
 [7]: http://blog.haohtml.com/wp-content/uploads/2011/06/tcp_query-flows-0.png