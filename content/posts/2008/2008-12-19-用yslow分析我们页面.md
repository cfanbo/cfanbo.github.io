---
title: 用YSlow分析我们页面
author: admin
type: post
date: 2008-12-19T06:32:36+00:00
excerpt: |
 YSlow是yahoo美国开发的一个页面评分插件，非常的棒，从中我们可以看出我们页面上的很多不足，并且可以知道我们改怎么却改进和优化。

 仔细研究了下YSlow跌评分规则。

 主要有12条：

 1. Make fewer HTTP requests 尽可能少的http请求。。我们有141个请求（其中15个JS请求，3个CSS请求，47个CSS background images请求），多的可怕。思考了下，为什么把这个三种请求过多列为对页面加载的重要不利因素呢，而过多的IMG请求并没有列为不利因素呢？
url: /archives/718
IM_contentdowned:
 - 1
categories:
 - 前端设计

---
YSlow是yahoo美国开发的一个页面评分插件，非常的棒，从中我们可以看出我们页面上的很多不足，并且可以知道我们改怎么却改进和优化。仔细研究了下YSlow跌评分规则。主要有12条：1. [Make fewer HTTP requests](http://developer.yahoo.com/performance/rules.html#num_http)尽可能少的http请求。。我们有141个请求（其中15个JS请求，3个CSS请求，47个CSS background images请求），多的可怕。思考了下，为什么把这个三种请求过多列为对页面加载的重要不利因素呢，而过多的IMG请求并没有列为不利因素呢？发现原来这些请求都是可以避免的。15个JS和3个CSS完全可以通过特殊的办法进行合并（这个技术部已经帮我们解决了，实在是太感谢了，嘿嘿。），这样合并以后，一般情况下页面上只会出现一个JS和一个CSS（对JS的封装得有一定的要求）。但是47个CSS background images请求改怎么解决呢？为什么页面上的纯IMG请求时合理的，而CSS background images请求过多就是不利因素了呢。这个我想了很久，总算明白，原来是这样的：一般页面上的ICON，栏目背景啊， 图片按钮啊，我们都会用图片CSS背景来实现，而一般这个图片CSS背景用到的图片都是比较小的，所以完全可以把这些图片合并成一个相对比较大的图片，这 样页面上只会出现一个CSS background images请求，最多也就2-3个。后来仔细看了下雅虎美国的页面，他们的确也是这样做的，虽然这样做需要花一定的时间来有规则的合并这些ICON，栏 目背景，图片按钮，以方便CSS调用，但是这样做绝对是合算的，而且是有必要的，YSlow也是极力推荐的。2. [Use a CDN](http://developer.yahoo.com/performance/rules.html#cdn)这 项我们的评分是F级，最低。说实在的，我刚开始什么是CDN都不知道。后来查了GOODLE才知道。CDN的全称是Content Delivery Network，即内容分发网络。其目的是通过在现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络”边缘”，使用户可 以就近取得所需的内容，解决Internet网络拥挤的状况，提高用户访问网站的响应速度。从技术上全面解决由于网络带宽小、用户访问量大、网点分布不均 等原因所造成的用户访问网站响应速度慢的问题。看来上述的解释后，基本上明白了 CDN是怎么回事，后来咨询了下中文站点SA，得知我们网站目前的确还没有做CDN的优化，但是据说我们有更加先进的技术来解决类似的问题（具体什么技术 那就保密了），但是毕竟CDN也是个相当不错的技术，所以在我们先进技术的基础上在做CDN优化，肯定比现在更好，嘿嘿。据说SA明年会做几个点的 CND。3. [Add an Expires header](http://developer.yahoo.com/performance/rules.html#expires) 设置过期的HTTP Header.设置Expires Header可以将脚本, 样式表, 图片, Flash等缓存在浏览器的Cache中.其实我们网站也做了这个优化，至少图 片在这个上做过优化，但是没有做完全。我们的CSS和JS都还没有做过优化，倒是外部引入的一个广告JS做了，呵呵。其实设置过期的HTTP Header 更应该做在脚本, 样式表, Flash上.不过据说这个SA也是没有做的，但是有一定的风险，因为JS和CSS是有一定的逻辑，如果服务器端和客户端都存在缓存的话，万一出了什么问 题，对我们以后查找问题的所在和增加难度，不过我想两者中是可以权衡和并存的。4. [Gzip components](http://developer.yahoo.com/performance/rules.html#gzip)对 我们的页面内容进行Gzip格式的压缩，Gzip格式是一种很普遍的压缩技术，几乎所有的浏览器都有解压Gzip格式的能力，而且它可以压缩的比例非常 大，一般压缩率为85%，就是说服务器端100K的页面可以压缩到25K左右的Gzip格式的数据发给客户端，客户端收到Gzip格式的数据后自动解压缩 后显示页面。这点我们网站基本上是100%做到了，但是我们这项的评分并没有达到想象中的A级，原因是出在我们的外部链接，比如我们首页，有外部的广告投放JS，这个JS说拥有的网站是没有做过GZIP优化，连累了我们网站，所以我们也只有B，或者C级。5. [Put CSS at the top](http://developer.yahoo.com/performance/rules.html#css_top)把CSS外部链接放到页面的顶部。其实这个原则我们一般都遵守的，如果 把CSS外部链接作为逻辑的一部分出现在页面头部以下，我个人觉得这个本身就是个错误。还好，我们的页面基本上都做到了，可是有些页面比如LIST页面， 还是出现了和逻辑挂钩的CSS链接，原因是为了解决一些本来就不合理的产品逻辑。所以，我们WEB前端工程师有义务杜绝这些不合理的产品逻辑破坏我们的页 面结果及页面加载速度，不能为了实现而实现。

6. [Put JS at the bottom](http://developer.yahoo.com/performance/rules.html#js_bottom) 把Javascript脚本尽量放到页面底部加载。

一开始为以为Javascript脚本尽量放到页面底部加载，是指所有的JS脚本都要放到底部，后来才发现，并不完全是这样，这里所指的脚本是指那 些在加载过程中要执行的脚本，所以一般的处理办法还是页面头部引入JS链接，页面底部执行JS脚本程序。为什么要这么做呢？呵呵，其实很简单，为了实现最 大的下载并行，页面加载初期做的事，最好只有下载，HTML的下载，CSS的下载,JS的下载，等下载完成后再去实现页面渲染，JS脚本运行。这个方面我 们还需要努力，很多页面我们在加载过程中运行了一部分脚本，或许是为了实现一些功能，没有办法，不过或许有更好的办法来替代呢。。。

7. [Avoid CSS expressions](http://developer.yahoo.com/performance/rules.html#css_expressions) 避免CSS表达式

其实在CSS中运行表达式和页面加载中运行大量的JS脚本差不多，或许还更慢，而且还不兼容，虽然可以使我们在页面逻辑简单不少，但是我们完全可以抛弃之。这个点，我们的页面基本上都做到了。不过说实话，CSS表达式，嘿嘿，我以前还不知道有这么回事。惭愧。哈哈。

9. [Reduce DNS lookups](http://developer.yahoo.com/performance/rules.html#dns_lookups) 尽可能少的DNS查找。

这项我们做的不是很好。D级，有9个域名，一般不要超过4个。不过这个主要是服务器架构上的问题，我们也无能为力，现在单单首页的广告域名就有好几 个，好耶的广告域名，雅虎的广告域名，淘宝店广告域名，打点的域名。如果去掉这些，我们其实还是够用的，一个主域名，一个图片的，一个STYLE的，最多 加上IFREAM的刚好4个。

10. [Minify JS 对Javascript](http://developer.yahoo.com/performance/rules.html#minify) 代码进行压缩。

这点我很早以前就对此关注了，也找到了一个不错的压缩工具，yuicompressor，雅虎美国开发的JAVA压缩包 yuicompressor.jar。压缩的相当完美，不仅把代码间的空格换行给去除掉了，而且对变量名，北部方法名都进行的简化，无意中实现了混淆脚本 的作用。现在我们仅仅做到了JS合并，并没有对齐进行压缩，如果我用yuicompressor手工的去压缩，虽然实现了JS压缩，但是给我们自己的维护 量增加了一倍，因为我们需要维护2套JS脚本，一套是压缩前的（调试用的），一套是压缩后（发布到网上的），而且要保证2套代码一致。所以最完美的做法是 在发布的时候实现JS脚本合并，并对其用yuicompressor进行压缩，然后发布到晚上，把关键点移到发布的时候，这样我们只需要关心一套JS脚本 （发布前的版本）。而且我觉得这个方案完全是行动通的。

11. [Avoid redirects](http://developer.yahoo.com/performance/rules.html#redirects) 避免重定向（跳转）

怎么理解这点呢？

我们经常遇到的一种做法，注册成功后，旺旺会有一个页面提示“你已经注册成功，3秒后将自动跳转到XX页面”。我就觉得很奇怪，你为什么不直接跳转到该去的页面？还有一种，我们大家非常熟悉，一般我们页面的链接都写成： [http://china.alibaba.com](http://china.alibaba.com/) 或者 [http://china.alibaba.com/](http://china.alibaba.com/),有人会问，有区别吗？我明确的告诉大家，有！服务器如果接收到的URL是 [http://china.alibaba.com](http://china.alibaba.com/)，它会自动重新定向到 [http://china.alibaba.com/](http://china.alibaba.com/)，虽然最后都打开了阿里巴巴中文站的首页，但是前者比后者多走了一步,重定向，显然多多少少浪费了一定的时间。所以以后我们加URL链接的时候，别忘了把最后的“/”给加上去。

12. [Remove duplicate scripts](http://developer.yahoo.com/performance/rules.html#js_dupes) 去除重复的脚本

这个其实没有什么好说的，大家都应该毫无条件的去遵守，但是越是明显，越是简单的事，我们往往会做不好，当然，很多理由的，项目时间太紧张了等等， 导致代码很乱，很多重复的地方。其实谁都知道重负不好，不过还好，我们的页面重复的脚本代码不多（至少一个页面里面，呵呵）。不过，我到是希望，我们不仅 要做到一个页面脚本不重复，而且要做到N个页面，脚本要重用。

13. [Configure ETags](http://developer.yahoo.com/performance/rules.html#etags) 这个好像是服务器端配置的问题，我不太懂，也就不乱说了，怕把大家给误导了。

总共13个，但是看了YAHOO的官方说明，好像还有一个AJAX CACHE(AJAX 缓存)。我倒是觉得这个很重要，随着我们AJAX应用的广泛，AJAX 缓存这个概念一定要时刻在我们脑子中，AJAX是个好东西，但是重复的数据，无休止的向后台申请，绝对是个错误（不仅是速度上还是对服务器压力上来说）， 所以我们就要对我们已经申请到的数据进行缓存，当第2次用到的时候，就直接从缓存中取，不要在去访问我们宝贵的服务器资源了。其实这个思想不仅仅适合 AJAX，在所有有数据复用的应用中都应该考虑到。

YSLOW就分析到这里完毕了，或许有些地方分析的不是很正确，或许有人分析的比我更早，更好，但是这些的确是我从工作中去积累，发现的，并很多都 实际应用到工作中去了，顺便说下，嘿嘿，LIST页面进行优化后，在0.92版本的YSLOW评分将达到76分，甚至80分，相当于0.8版本的90分以 上。不过评分毕竟是评分，关键还是速度。