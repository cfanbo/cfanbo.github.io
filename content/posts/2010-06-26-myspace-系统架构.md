---
title: MySpace 系统架构
author: admin
type: post
date: 2010-06-26T16:17:04+00:00
url: /archives/4057
IM_contentdowned:
 - 1
categories:
 - 前端设计
tags:
 - 系统架构

---
在前不久结束的 [QCon 2008][1] 上，MySpace 的首席架构师 [Dan Farino][2] 做了题为 [Behind the Scenes at MySpace.com][3] (PDF 下载)的技术演讲。

#### 架构概况

超过 4,500 台 Web 服务器，配置为 Windows 2003/IIS 6.0/ASP.NET ；超过 1200 台 Cache 服务器，64 位的 Windows 2003，超过 500 台的数据库服务器，配置为 64 位的 Windows 2003，数据库为 SQL Server 2005 。

之前曾有一篇 [揭 秘 MySpace 架构][4]的文章，也有中文版本《 [亿万用户网站 MySpace的成功秘密](http://www.kuqin.com/system-analysis/20071230/3238.html)》！

#### 运维数据收集

其实这个演讲我感觉主要讲的是这个数据收集模块 🙂 MySpace 的方案倒是让我们看到了在超大规模的 Windows 环境下如何进行数据收集的。

[![myspace系统架构](http://blog.haohtml.com/wp-content/uploads/2010/06/1626170.png)][5]

每个客户端通过一个 TCP 连接到收集上服务器。收集的信息包括：Windows 性能计数器 Performance Counters、 WMI 对象(定制后的 WMI 对象)、事件日志、 硬件数据等等。收集器服务(Agent) 用 C#实现的，完全的异步 I/O，用了微软的 Concurrency and Coordination Runtime 库。每台主机上一个 Agent。其实国内也有超大规模的 Windows 环境 — 比如盛大，数据采集和监控的机制倒是类似的。

数据协议用的 Google 的 [Protocol buffers][6]。这倒是看到 Google 的这玩意儿公开后第一家大站点在用。也是因为用 Protocol buffers 从而不用 XMPP+ejabberd 的消息处理方案。

QCon 是我非常心仪的技术会议。可惜今年因为客观原因没能组织同事去参加。期待 2009 年[在伦敦][7]的会议。

–EOF–

本文出自：[http://www.dbanotes.net/arch/myspace\_arch\_2008.html][8]

 [1]: http://qconsf.com/
 [2]: http://jaoo.dk/london-2008/speaker/Dan+Farino
 [3]: http://qconsf.com/sf2008/file?path=/qcon-sanfran-2008/slides//DanFarino_Myspace.pdf
 [4]: http://www.baselinemag.com/c/a/Projects-Networks-and-Storage/Inside-MySpacecom/
 [5]: http://blog.haohtml.com/wp-content/uploads/2010/06/1626170.png
 [6]: http://code.google.com/apis/protocolbuffers/docs/overview.html
 [7]: http://qconlondon.com/
 [8]: http://www.dbanotes.net/arch/myspace_arch_2008.html