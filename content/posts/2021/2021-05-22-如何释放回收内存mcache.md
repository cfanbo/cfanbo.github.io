---
title: 如何释放回收内存mcache
author: admin
type: post
date: 2021-05-22T14:02:54+00:00
draft: true
private: true
url: /archives/30739
categories:
 - 程序开发

---
在上节《 [GC 对根对象扫描实现的源码分析](https://blog.haohtml.com/archives/27003#%E9%87%8A%E6%94%BEmcache)》介绍过在进行gc的时候，会从根对象开始进行相关资源的回收，基中有一项就是对mcache的回收。

建议先了解一下内存组件 `mcache` 的数据结构《 [Golang 内存组件之mspan、mcache、mcentral 和 mheap 数据结构](https://blog.haohtml.com/archives/29385)》。

```
func flushmcache(i int) {
    assertWorldStopped()

    p := allp[i]
    c := p.mcache
    if c == nil {
        return
    }
    c.releaseAll()
    stackcache_clear(c)
}
```

每次释放一个p下面的mcache，主要关注的是 ` [c.releaseAll()](https://github.com/golang/go/blob/go1.16.3/src/runtime/mcache.go#L251-L290) ` 和 [`stackcache_clear()`](https://github.com/golang/go/blob/go1.16.3/src/runtime/stack.go#L302-L319) 函数。

```
func (c *mcache) releaseAll() {
	// Take this opportunity to flush scanAlloc.
	// 更新 memstats.heap_scan 统计，即已扫描的堆的大小
	atomic.Xadd64(&memstats.heap_scan, int64(c.scanAlloc))
	c.scanAlloc = 0

	sg := mheap_.sweepgen

	// c.alloc 表示p下面的不同规格内存
	for i := range c.alloc {
		s := c.alloc[i]
		if s != &emptymspan {
			// Adjust nsmallalloc in case the span wasn't fully allocated.
			// s.elems 表示规格span中的总对象数量； s.allocCount 表示已分配的对象数量
			n := uintptr(s.nelems) - uintptr(s.allocCount)

			// 计算小对象的alloc数量
			stats := memstats.heapStats.acquire()
			atomic.Xadduintptr(&stats.smallAllocCount[spanClass(i).sizeclass()], -n)
			memstats.heapStats.release()

			// GC相关
			if s.sweepgen != sg+1 {
				// refill conservatively counted unallocated slots in heap_live.
				// Undo this.
				//
				// If this span was cached before sweep, then
				// heap_live was totally recomputed since
				// caching this span, so we don't do this for
				// stale spans.
				atomic.Xadd64(&memstats.heap_live, -int64(n)*int64(s.elemsize))
			}

			// Release the span to the mcentral.
			// 释放mspan 到 mcentral 中，并标记当前规格内存为 emptymspan
			mheap_.central[i].mcentral.uncacheSpan(s)
			c.alloc[i] = &emptymspan
		}
	}

	// Clear tinyalloc pool.
	// 清除 tinyalloc 微对象，并更新统计 memstats.tinyallocs
	c.tiny = 0
	c.tinyoffset = 0
	atomic.Xadd64(&memstats.tinyallocs, int64(c.tinyAllocs))
	c.tinyAllocs = 0

	// Updated heap_scan and possible heap_live.
	if gcBlackenEnabled != 0 {
		gcController.revise()
	}
}
```

`c.alloc` 是一个数组类型，存储了每种规格大小的内存，定义在 `mcache` 结构体中

```
alloc [numSpanClasses]*mspan // spans to allocate from, indexed by spanClass
```

释放流程

 * 遍历每个p.mcache下面的每种规格的内存 `c.alloc[i]`
 * 根据span中总对象数量和已分配对象数量，计算并更新统计堆中不同规格的内存分配数量 `heapStatsDelta.smallAllocCount[规格]`
 * 将 span 放回 `mheap_.central[i].mcentral` 中，同时标记当前规格内存为 `emptyspan`，表示不包含任何对象
 * 清除 `tinyalloc` 对象

从整体视角来看的话，主要释放 `alloc` 对象和 `tiny` 对象即可，alloc 是一个数组，所以需要遍历释放。

这里对于 alloc 对象是需要放回 `mentral` 对象，那么我们再看下它是如何实现的。

对于 ` [mentral.uncacheSpan()](https://github.com/golang/go/blob/go1.16.3/src/runtime/mcentral.go#L184-L225) ` 的定义如下：

```
// Return span from an mcache.
//
// s must have a span class corresponding to this
// mcentral and it must not be empty.
func (c *mcentral) uncacheSpan(s *mspan) {
	......

	if stale {
		......
	} else {
		if int(s.nelems)-int(s.allocCount) > 0 {
			// Put it back on the partial swept list.
			c.partialSwept(sg).push(s)
		} else {
			// There's no free space and it's not stale, so put it on the
			// full swept list.
			c.fullSwept(sg).push(s)
		}
	}
}
```

这里根据条件 `是否存在未使用的内存对象` 来决定是将 span 放在部分扫描队列还是完整扫描队列。

如何理解这块呢？我们再看下`mcentral` 结构体的定义

```
type mcentral struct {
    spanclass spanClass
    partial [2]spanSet // list of spans with a free object
    full    [2]spanSet // list of spans with no free objects
}
```

 * `spanClass` 指当前规格大小
 * `partial` 存在空闲对象spans列表
 * `full` 无空闲对象spans列表

可以看到，如果当前释放的内存中存在未使用的对象，则放在 `mcentral.partial` 中，如果没有空闲对象的话，就放在 `mcentral.full` 中。

`spans` 是一个双向链表数据结构，我们再看下它的放入过程，

在其之前，我们先看一下 `spanSet` 数据结构

```
type spanSet struct {
	spineLock mutex
	spine     unsafe.Pointer // *[N]*spanSetBlock, accessed atomically
	spineLen  uintptr        // Spine array length, accessed atomically
	spineCap  uintptr        // Spine array cap, accessed under lock
	index headTailIndex
}
```

对它的定义是在 ` [spanSet.push()](https://github.com/golang/go/blob/go1.16.3/src/runtime/mspanset.go#L72-L137) ` 中实现的。

```
// push adds span s to buffer b. push is safe to call concurrently
// with other push and pop operations.
func (b *spanSet) push(s *mspan) {
	// Obtain our slot.
	cursor := uintptr(b.index.incTail().tail() - 1)
	top, bottom := cursor/spanSetBlockEntries, cursor%spanSetBlockEntries

	// Do we need to add a block?
	spineLen := atomic.Loaduintptr(&b.spineLen)
	var block *spanSetBlock
retry:
	if top < spineLen {
		spine := atomic.Loadp(unsafe.Pointer(&b.spine))
		blockp := add(spine, sys.PtrSize*top)
		block = (*spanSetBlock)(atomic.Loadp(blockp))
	} else {
		// Add a new block to the spine, potentially growing
		// the spine.
		lock(&b.spineLock)
		// spineLen cannot change until we release the lock,
		// but may have changed while we were waiting.
		spineLen = atomic.Loaduintptr(&b.spineLen)
		if top < spineLen {
			unlock(&b.spineLock)
			goto retry
		}

		if spineLen == b.spineCap {
			// Grow the spine.
			newCap := b.spineCap * 2
			if newCap == 0 {
				newCap = spanSetInitSpineCap
			}
			newSpine := persistentalloc(newCap*sys.PtrSize, cpu.CacheLineSize, &memstats.gcMiscSys)
			if b.spineCap != 0 {
				// Blocks are allocated off-heap, so
				// no write barriers.
				memmove(newSpine, b.spine, b.spineCap*sys.PtrSize)
			}
			// Spine is allocated off-heap, so no write barrier.
			atomic.StorepNoWB(unsafe.Pointer(&b.spine), newSpine)
			b.spineCap = newCap
			// We can't immediately free the old spine
			// since a concurrent push with a lower index
			// could still be reading from it. We let it
			// leak because even a 1TB heap would waste
			// less than 2MB of memory on old spines. If
			// this is a problem, we could free old spines
			// during STW.
		}

		// Allocate a new block from the pool.
		block = spanSetBlockPool.alloc()

		// Add it to the spine.
		blockp := add(b.spine, sys.PtrSize*top)
		// Blocks are allocated off-heap, so no write barrier.
		atomic.StorepNoWB(blockp, unsafe.Pointer(block))
		atomic.Storeuintptr(&b.spineLen, spineLen+1)
		unlock(&b.spineLock)
	}

	// We have a block. Insert the span atomically, since there may be
	// concurrent readers via the block API.
	atomic.StorepNoWB(unsafe.Pointer(&block.spans[bottom]), unsafe.Pointer(s))
}
```

除了 mcache.releaseAll() 外还调用另一个函数 stackcache_clear(mcache).

```
//go:systemstack
func stackcache_clear(c *mcache) {
	for order := uint8(0); order < _NumStackOrders; order++ {
		lock(&stackpool[order].item.mu)
		x := c.stackcache[order].list
		for x.ptr() != nil {
			y := x.ptr().next
			stackpoolfree(x, order)
			x = y
		}
		c.stackcache[order].list = 0
		c.stackcache[order].size = 0
		unlock(&stackpool[order].item.mu)
	}
}
```

` [stackcache](https://github.com/golang/go/blob/go1.16.3/src/runtime/stack.go#L137-L144) ` 一个全局变量，定义如下

```
var stackpool [_NumStackOrders]struct {
	item stackpoolItem
	_    [cpu.CacheLinePadSize - unsafe.Sizeof(stackpoolItem{})%cpu.CacheLinePadSize]byte
}
//go:notinheap
type stackpoolItem struct {
	mu   mutex
	span mSpanList
}
```

中间调用 ` [stackpoolfree()](https://github.com/golang/go/blob/go1.16.3/src/runtime/stack.go#L222-L256) ` 函数。