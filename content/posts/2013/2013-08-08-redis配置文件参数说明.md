---
title: Redisé…ç½®æ–‡ä»¶å‚æ•°è¯´æ˜Ž
author: admin
type: post
date: 2013-08-08T10:00:01+00:00
url: /archives/14195
categories:
 - ç³»ç»Ÿæž¶æž„
tags:
 - redis

---
**é…ç½®æ–‡ä»¶å‚æ•°è¯´æ˜Ž**:

1. Redisé»˜è®¤ä¸æ˜¯ä»¥å®ˆæŠ¤è¿›ç¨‹çš„æ–¹å¼è¿è¡Œï¼Œå¯ä»¥é€šè¿‡è¯¥é…ç½®é¡¹ä¿®æ”¹ï¼Œä½¿ç”¨yeså¯ç”¨å®ˆæŠ¤è¿›ç¨‹

**daemonize no**

2. å½“Redisä»¥å®ˆæŠ¤è¿›ç¨‹æ–¹å¼è¿è¡Œæ—¶ï¼ŒRedisé»˜è®¤ä¼šæŠŠpidå†™å…¥/var/run/redis.pidæ–‡ä»¶ï¼Œå¯ä»¥é€šè¿‡pidfileæŒ‡å®š

**pidfile /var/run/redis.pid**

3. æŒ‡å®šRedisç›‘å¬ç«¯å£ï¼Œé»˜è®¤ç«¯å£ä¸º6379ï¼Œä½œè€…åœ¨è‡ªå·±çš„ä¸€ç¯‡åšæ–‡ä¸­è§£é‡Šäº†ä¸ºä»€ä¹ˆé€‰ç”¨6379ä½œä¸ºé»˜è®¤ç«¯å£ï¼Œå› ä¸º6379åœ¨æ‰‹æœºæŒ‰é”®ä¸ŠMERZå¯¹åº”çš„å·ç ï¼Œè€ŒMERZå–è‡ªæ„å¤§åˆ©æ­Œå¥³Alessia Merzçš„åå­—

** port 6379**

4. ç»‘å®šçš„ä¸»æœºåœ°å€

**bind 127.0.0.1**

5.å½“ å®¢æˆ·ç«¯é—²ç½®å¤šé•¿æ—¶é—´åŽå…³é—­è¿žæŽ¥ï¼Œå¦‚æžœæŒ‡å®šä¸º0ï¼Œè¡¨ç¤ºå…³é—­è¯¥åŠŸèƒ½

**timeout 300**

6. æŒ‡å®šæ—¥å¿—è®°å½•çº§åˆ«ï¼ŒRedisæ€»å…±æ”¯æŒå››ä¸ªçº§åˆ«ï¼šdebugã€verboseã€noticeã€warningï¼Œé»˜è®¤ä¸ºverbose

**loglevel verbose**

7. æ—¥å¿—è®°å½•æ–¹å¼ï¼Œé»˜è®¤ä¸ºæ ‡å‡†è¾“å‡ºï¼Œå¦‚æžœé…ç½®Redisä¸ºå®ˆæŠ¤è¿›ç¨‹æ–¹å¼è¿è¡Œï¼Œè€Œè¿™é‡Œåˆé…ç½®ä¸ºæ—¥å¿—è®°å½•æ–¹å¼ä¸ºæ ‡å‡†è¾“å‡ºï¼Œåˆ™æ—¥å¿—å°†ä¼šå‘é€ç»™/dev/null

**logfile stdout**

8. è®¾ç½®æ•°æ®åº“çš„æ•°é‡ï¼Œé»˜è®¤æ•°æ®åº“ä¸º0ï¼Œå¯ä»¥ä½¿ç”¨SELECT å‘½ä»¤åœ¨è¿žæŽ¥ä¸ŠæŒ‡å®šæ•°æ®åº“id

**databases 16**

9. æŒ‡å®šåœ¨å¤šé•¿æ—¶é—´å†…ï¼Œæœ‰å¤šå°‘æ¬¡æ›´æ–°æ“ä½œï¼Œå°±å°†æ•°æ®åŒæ­¥åˆ°æ•°æ®æ–‡ä»¶ï¼Œå¯ä»¥å¤šä¸ªæ¡ä»¶é…åˆ

**save **

Redisé»˜è®¤é…ç½®æ–‡ä»¶ä¸­æä¾›äº†ä¸‰ä¸ªæ¡ä»¶ï¼š

**save 900 1**

**save 300 10**

**save 60 10000**

åˆ†åˆ«è¡¨ç¤º900ç§’ï¼ˆ15åˆ†é’Ÿï¼‰å†…æœ‰1ä¸ªæ›´æ”¹ï¼Œ300ç§’ï¼ˆ5åˆ†é’Ÿï¼‰å†…æœ‰10ä¸ªæ›´æ”¹ä»¥åŠ60ç§’å†…æœ‰10000ä¸ªæ›´æ”¹ã€‚

10. æŒ‡å®šå­˜å‚¨è‡³æœ¬åœ°æ•°æ®åº“æ—¶æ˜¯å¦åŽ‹ç¼©æ•°æ®ï¼Œé»˜è®¤ä¸ºyesï¼ŒRedisé‡‡ç”¨LZFåŽ‹ç¼©ï¼Œå¦‚æžœä¸ºäº†èŠ‚çœCPUæ—¶é—´ï¼Œå¯ä»¥å…³é—­è¯¥é€‰é¡¹ï¼Œä½†ä¼šå¯¼è‡´æ•°æ®åº“æ–‡ä»¶å˜çš„å·¨å¤§

**rdbcompression yes**

11. æŒ‡å®šæœ¬åœ°æ•°æ®åº“æ–‡ä»¶åï¼Œé»˜è®¤å€¼ä¸ºdump.rdb

**dbfilename dump.rdb**

12. æŒ‡å®šæœ¬åœ°æ•°æ®åº“å­˜æ”¾ç›®å½•

**dir ./**

13. è®¾ç½®å½“æœ¬æœºä¸ºslavæœåŠ¡æ—¶ï¼Œè®¾ç½®masteræœåŠ¡çš„IPåœ°å€åŠç«¯å£ï¼Œåœ¨Rediså¯åŠ¨æ—¶ï¼Œå®ƒä¼šè‡ªåŠ¨ä»Žmasterè¿›è¡Œæ•°æ®åŒæ­¥

**slaveof **

14. å½“masteræœåŠ¡è®¾ç½®äº†å¯†ç ä¿æŠ¤æ—¶ï¼ŒslavæœåŠ¡è¿žæŽ¥masterçš„å¯†ç 

**masterauth **

15. è®¾ç½®Redisè¿žæŽ¥å¯†ç ï¼Œå¦‚æžœé…ç½®äº†è¿žæŽ¥å¯†ç ï¼Œå®¢æˆ·ç«¯åœ¨è¿žæŽ¥Redisæ—¶éœ€è¦é€šè¿‡AUTH å‘½ä»¤æä¾›å¯†ç ï¼Œé»˜è®¤å…³é—­

**requirepass foobared**

16. è®¾ç½®åŒä¸€æ—¶é—´æœ€å¤§å®¢æˆ·ç«¯è¿žæŽ¥æ•°ï¼Œé»˜è®¤æ— é™åˆ¶ï¼ŒRediså¯ä»¥åŒæ—¶æ‰“å¼€çš„å®¢æˆ·ç«¯è¿žæŽ¥æ•°ä¸ºRedisè¿›ç¨‹å¯ä»¥æ‰“å¼€çš„æœ€å¤§æ–‡ä»¶æè¿°ç¬¦æ•°ï¼Œå¦‚æžœè®¾ç½® maxclients 0ï¼Œè¡¨ç¤ºä¸ä½œé™åˆ¶ã€‚å½“å®¢æˆ·ç«¯è¿žæŽ¥æ•°åˆ°è¾¾é™åˆ¶æ—¶ï¼ŒRedisä¼šå…³é—­æ–°çš„è¿žæŽ¥å¹¶å‘å®¢æˆ·ç«¯è¿”å›žmax number of clients reachedé”™è¯¯ä¿¡æ¯

**maxclients 128**

17. æŒ‡å®šRedisæœ€å¤§å†…å­˜é™åˆ¶ï¼ŒRedisåœ¨å¯åŠ¨æ—¶ä¼šæŠŠæ•°æ®åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œè¾¾åˆ°æœ€å¤§å†…å­˜åŽï¼ŒRedisä¼šå…ˆå°è¯•æ¸…é™¤å·²åˆ°æœŸæˆ–å³å°†åˆ°æœŸçš„Keyï¼Œå½“æ­¤æ–¹æ³•å¤„ç† åŽï¼Œä»ç„¶åˆ°è¾¾æœ€å¤§å†…å­˜è®¾ç½®ï¼Œå°†æ— æ³•å†è¿›è¡Œå†™å…¥æ“ä½œï¼Œä½†ä»ç„¶å¯ä»¥è¿›è¡Œè¯»å–æ“ä½œã€‚Redisæ–°çš„vmæœºåˆ¶ï¼Œä¼šæŠŠKeyå­˜æ”¾å†…å­˜ï¼ŒValueä¼šå­˜æ”¾åœ¨swapåŒº

**maxmemory **

18. æŒ‡å®šæ˜¯å¦åœ¨æ¯æ¬¡æ›´æ–°æ“ä½œåŽè¿›è¡Œæ—¥å¿—è®°å½•ï¼ŒRedisåœ¨é»˜è®¤æƒ…å†µä¸‹æ˜¯å¼‚æ­¥çš„æŠŠæ•°æ®å†™å…¥ç£ç›˜ï¼Œå¦‚æžœä¸å¼€å¯ï¼Œå¯èƒ½ä¼šåœ¨æ–­ç”µæ—¶å¯¼è‡´ä¸€æ®µæ—¶é—´å†…çš„æ•°æ®ä¸¢å¤±ã€‚å› ä¸º redisæœ¬èº«åŒæ­¥æ•°æ®æ–‡ä»¶æ˜¯æŒ‰ä¸Šé¢saveæ¡ä»¶æ¥åŒæ­¥çš„ï¼Œæ‰€ä»¥æœ‰çš„æ•°æ®ä¼šåœ¨ä¸€æ®µæ—¶é—´å†…åªå­˜åœ¨äºŽå†…å­˜ä¸­ã€‚é»˜è®¤ä¸ºno

**appendonly no**

19. æŒ‡å®šæ›´æ–°æ—¥å¿—æ–‡ä»¶åï¼Œé»˜è®¤ä¸ºappendonly.aof

**appendfilename appendonly.aof**

20. æŒ‡å®šæ›´æ–°æ—¥å¿—æ¡ä»¶ï¼Œå…±æœ‰3ä¸ªå¯é€‰å€¼ï¼š
**no**ï¼šè¡¨ç¤ºç­‰æ“ä½œç³»ç»Ÿè¿›è¡Œæ•°æ®ç¼“å­˜åŒæ­¥åˆ°ç£ç›˜ï¼ˆå¿«ï¼‰
**always**ï¼šè¡¨ç¤ºæ¯æ¬¡æ›´æ–°æ“ä½œåŽæ‰‹åŠ¨è°ƒç”¨fsync()å°†æ•°æ®å†™åˆ°ç£ç›˜ï¼ˆæ…¢ï¼Œå®‰å…¨ï¼‰
**everysec**ï¼šè¡¨ç¤ºæ¯ç§’åŒæ­¥ä¸€æ¬¡ï¼ˆæŠ˜è¡·ï¼Œé»˜è®¤å€¼ï¼‰

**appendfsync everysec**

21. æŒ‡å®šæ˜¯å¦å¯ç”¨è™šæ‹Ÿå†…å­˜æœºåˆ¶ï¼Œé»˜è®¤å€¼ä¸ºnoï¼Œç®€å•çš„ä»‹ç»ä¸€ä¸‹ï¼ŒVMæœºåˆ¶å°†æ•°æ®åˆ†é¡µå­˜æ”¾ï¼Œç”±Rediså°†è®¿é—®é‡è¾ƒå°‘çš„é¡µå³å†·æ•°æ®swapåˆ°ç£ç›˜ä¸Šï¼Œè®¿é—®å¤šçš„é¡µé¢ç”±ç£ç›˜è‡ªåŠ¨æ¢å‡ºåˆ°å†…å­˜ä¸­ï¼ˆåœ¨åŽé¢çš„æ–‡ç« æˆ‘ä¼šä»”ç»†åˆ†æžRedisçš„VMæœºåˆ¶ï¼‰

**vm-enabled no**

22. è™šæ‹Ÿå†…å­˜æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤å€¼ä¸º/tmp/redis.swapï¼Œä¸å¯å¤šä¸ªRediså®žä¾‹å…±äº«

**vm-swap-file /tmp/redis.swap**

23. å°†æ‰€æœ‰å¤§äºŽvm-max-memoryçš„æ•°æ®å­˜å…¥è™šæ‹Ÿå†…å­˜,æ— è®ºvm-max-memoryè®¾ç½®å¤šå°,æ‰€æœ‰ç´¢å¼•æ•°æ®éƒ½æ˜¯å†…å­˜å­˜å‚¨çš„(Redisçš„ç´¢å¼•æ•°æ® å°±æ˜¯keys),ä¹Ÿå°±æ˜¯è¯´,å½“vm-max-memoryè®¾ç½®ä¸º0çš„æ—¶å€™,å…¶å®žæ˜¯æ‰€æœ‰valueéƒ½å­˜åœ¨äºŽç£ç›˜ã€‚é»˜è®¤å€¼ä¸º0

**vm-max-memory 0**

24. Redis swapæ–‡ä»¶åˆ†æˆäº†å¾ˆå¤šçš„pageï¼Œä¸€ä¸ªå¯¹è±¡å¯ä»¥ä¿å­˜åœ¨å¤šä¸ªpageä¸Šé¢ï¼Œä½†ä¸€ä¸ªpageä¸Šä¸èƒ½è¢«å¤šä¸ªå¯¹è±¡å…±äº«ï¼Œvm-page-sizeæ˜¯è¦æ ¹æ®å­˜å‚¨çš„ æ•°æ®å¤§å°æ¥è®¾å®šçš„ï¼Œä½œè€…å»ºè®®å¦‚æžœå­˜å‚¨å¾ˆå¤šå°å¯¹è±¡ï¼Œpageå¤§å°æœ€å¥½è®¾ç½®ä¸º32æˆ–è€…64bytesï¼›å¦‚æžœå­˜å‚¨å¾ˆå¤§å¤§å¯¹è±¡ï¼Œåˆ™å¯ä»¥ä½¿ç”¨æ›´å¤§çš„pageï¼Œå¦‚æžœä¸ ç¡®å®šï¼Œå°±ä½¿ç”¨é»˜è®¤å€¼

**vm-page-size 32**

25. è®¾ç½®swapæ–‡ä»¶ä¸­çš„pageæ•°é‡ï¼Œç”±äºŽé¡µè¡¨ï¼ˆä¸€ç§è¡¨ç¤ºé¡µé¢ç©ºé—²æˆ–ä½¿ç”¨çš„bitmapï¼‰æ˜¯åœ¨æ”¾åœ¨å†…å­˜ä¸­çš„ï¼Œï¼Œåœ¨ç£ç›˜ä¸Šæ¯8ä¸ªpageså°†æ¶ˆè€—1byteçš„å†…å­˜ã€‚

**vm-pages 134217728**

26. è®¾ç½®è®¿é—®swapæ–‡ä»¶çš„çº¿ç¨‹æ•°,æœ€å¥½ä¸è¦è¶…è¿‡æœºå™¨çš„æ ¸æ•°,å¦‚æžœè®¾ç½®ä¸º0,é‚£ä¹ˆæ‰€æœ‰å¯¹swapæ–‡ä»¶çš„æ“ä½œéƒ½æ˜¯ä¸²è¡Œçš„ï¼Œå¯èƒ½ä¼šé€ æˆæ¯”è¾ƒé•¿æ—¶é—´çš„å»¶è¿Ÿã€‚é»˜è®¤å€¼ä¸º4

**vm-max-threads 4**

27. è®¾ç½®åœ¨å‘å®¢æˆ·ç«¯åº”ç­”æ—¶ï¼Œæ˜¯å¦æŠŠè¾ƒå°çš„åŒ…åˆå¹¶ä¸ºä¸€ä¸ªåŒ…å‘é€ï¼Œé»˜è®¤ä¸ºå¼€å¯

**glueoutputbuf yes**

28. æŒ‡å®šåœ¨è¶…è¿‡ä¸€å®šçš„æ•°é‡æˆ–è€…æœ€å¤§çš„å…ƒç´ è¶…è¿‡æŸä¸€ä¸´ç•Œå€¼æ—¶ï¼Œé‡‡ç”¨ä¸€ç§ç‰¹æ®Šçš„å“ˆå¸Œç®—æ³•

**hash-max-zipmap-entries 64**

**hash-max-zipmap-value 512**

29. æŒ‡å®šæ˜¯å¦æ¿€æ´»é‡ç½®å“ˆå¸Œï¼Œé»˜è®¤ä¸ºå¼€å¯ï¼ˆåŽé¢åœ¨ä»‹ç»Redisçš„å“ˆå¸Œç®—æ³•æ—¶å…·ä½“ä»‹ç»ï¼‰

**activerehashing yes**

30. æŒ‡å®šåŒ…å«å…¶å®ƒçš„é…ç½®æ–‡ä»¶ï¼Œå¯ä»¥åœ¨åŒä¸€ä¸»æœºä¸Šå¤šä¸ªRediså®žä¾‹ä¹‹é—´ä½¿ç”¨åŒä¸€ä»½é…ç½®æ–‡ä»¶ï¼Œè€ŒåŒæ—¶å„ä¸ªå®žä¾‹åˆæ‹¥æœ‰è‡ªå·±çš„ç‰¹å®šé…ç½®æ–‡ä»¶

**include /path/to/local.conf**

=============================================================

[java]
\# Redis configuration file example

\# Note on units: when memory size is needed, it is possible to specifiy
\# it in the usual form of 1k 5GB 4M and so forth:
#
\# 1k => 1000 bytes
\# 1kb => 1024 bytes
\# 1m => 1000000 bytes
\# 1mb => 1024*1024 bytes
\# 1g => 1000000000 bytes
\# 1gb => 1024\*1024\*1024 bytes
#
\# units are case insensitive so 1GB 1Gb 1gB are all the same.

\# By default Redis does not run as a daemon. Use â€˜yesâ€™ if you need it.
\# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.
daemonize yes

\# When running daemonized, Redis writes a pid file in /var/run/redis.pid by
\# default. You can specify a custom pid file location here.
pidfile /usr/local/redis/run/redis.pid

\# Accept connections on the specified port, default is 6379
port 6379

\# If you want you can bind a single interface, if the bind option is not
\# specified all the interfaces will listen for incoming connections.
#
#bind 192.168.20.12

\# Close the connection after a client is idle for N seconds (0 to disable)
timeout 300

\# Set server verbosity to â€˜debugâ€™
\# it can be one of:
\# debug (a lot of information, useful for development/testing)
\# verbose (many rarely useful info, but not a mess like the debug level)
\# notice (moderately verbose, what you want in production probably)
\# warning (only very important / critical messages are logged)
loglevel verbose

\# Specify the log file name. Also â€˜stdoutâ€™ can be used to force
\# Redis to log on the standard output. Note that if you use standard
\# output for logging but daemonize, logs will be sent to /dev/null
#logfile stdout
logfile ./logs/redis.log

\# Set the number of databases. The default database is DB 0, you can select
\# a different one on a per-connection basis using SELECT where
\# dbid is a number between 0 and â€˜databasesâ€™-1
databases 16

################################ SNAPSHOTTING #################################
#
\# Save the DB on disk:
#
\# save
#
\# Will save the DB if both the given number of seconds and the given
\# number of write operations against the DB occurred.
#
\# In the example below the behaviour will be to save:
\# after 900 sec (15 min) if at least 1 key changed
\# after 300 sec (5 min) if at least 10 keys changed
\# after 60 sec if at least 10000 keys changed
#
\# Note: you can disable saving at all commenting all the "save" lines.

save 900 1
save 300 10
save 60 10000

\# Compress string objects using LZF when dump .rdb databases?
\# For default thatâ€™s set to â€˜yesâ€™ as itâ€™s almost always a win.
\# If you want to save some CPU in the saving child set it to â€˜noâ€™ but
\# the dataset will likely be bigger if you have compressible values or keys.
rdbcompression yes

\# The filename where to dump the DB
dbfilename dump.rdb

\# The working directory.
#
\# The DB will be written inside this directory, with the filename specified
\# above using the â€˜dbfilenameâ€™ configuration directive.
#
\# Also the Append Only File will be created inside this directory.
#
\# Note that you must specify a directory here, not a file name.
dir ./data/

################################# REPLICATION #################################

\# Master-Slave replication. Use slaveof to make a Redis instance a copy of
\# another Redis server. Note that the configuration is local to the slave
\# so for example it is possible to configure the slave to save the DB with a
\# different interval, or to listen to another port, and so on.
#
\# slaveof

\# If the master is password protected (using the "requirepass" configuration
\# directive below) it is possible to tell the slave to authenticate before
\# starting the replication synchronization process, otherwise the master will
\# refuse the slave request.
#
\# masterauth

################################## SECURITY ###################################

\# Require clients to issue AUTH before processing any other
\# commands. This might be useful in environments in which you do not trust
\# others with access to the host running redis-server.
#
\# This should stay commented out for backward compatibility and because most
\# people do not need auth (e.g. they run their own servers).
#
\# Warning: since Redis is pretty fast an outside user can try up to
\# 150k passwords per second against a good box. This means that you should
\# use a very strong password otherwise it will be very easy to break.
#
\# requirepass foobared

################################### LIMITS ####################################

\# Set the max number of connected clients at the same time. By default there
\# is no limit, and itâ€™s up to the number of file descriptors the Redis process
\# is able to open. The special value â€˜0â€™ means no limits.
\# Once the limit is reached Redis will close all the new connections sending
\# an error â€˜max number of clients reachedâ€™.
#
\# maxclients 128

\# Donâ€™t use more memory than the specified amount of bytes.
\# When the memory limit is reached Redis will try to remove keys with an
\# EXPIRE set. It will try to start freeing keys that are going to expire
\# in little time and preserve keys with a longer time to live.
\# Redis will also try to remove objects from free lists if possible.
#
\# If all this fails, Redis will start to reply with errors to commands
\# that will use more memory, like SET, LPUSH, and so on, and will continue
\# to reply to most read-only commands like GET.
#
\# WARNING: maxmemory can be a good idea mainly if you want to use Redis as a
\# â€˜stateâ€™ server or cache, not as a real DB. When Redis is used as a real
\# database the memory usage will grow over the weeks, it will be obvious if
\# it is going to use too much memory in the long run, and youâ€™ll have the time
\# to upgrade. With maxmemory after the limit is reached youâ€™ll start to get
\# errors for write operations, and this may even lead to DB inconsistency.
#
\# maxmemory

############################## APPEND ONLY MODE ###############################

\# By default Redis asynchronously dumps the dataset on disk. If you can live
\# with the idea that the latest records will be lost if something like a crash
\# happens this is the preferred way to run Redis. If instead you care a lot
\# about your data and donâ€™t want to that a single record can get lost you should
\# enable the append only mode: when this mode is enabled Redis will append
\# every write operation received in the file appendonly.aof. This file will
\# be read on startup in order to rebuild the full dataset in memory.
#
\# Note that you can have both the async dumps and the append only file if you
\# like (you have to comment the "save" statements above to disable the dumps).
\# Still if append only mode is enabled Redis will load the data from the
\# log file at startup ignoring the dump.rdb file.
#
\# IMPORTANT: Check the BGREWRITEAOF to check how to rewrite the append
\# log file in background when it gets too big.

appendonly yes

\# The name of the append only file (default: "appendonly.aof")
appendfilename appendonly.aof

\# The fsync() call tells the Operating System to actually write data on disk
\# instead to wait for more data in the output buffer. Some OS will really flush
\# data on disk, some other OS will just try to do it ASAP.
#
\# Redis supports three different modes:
#
\# no: donâ€™t fsync, just let the OS flush the data when it wants. Faster.
\# always: fsync after every write to the append only log . Slow, Safest.
\# everysec: fsync only if one second passed since the last fsync. Compromise.
#
\# The default is "everysec" thatâ€™s usually the right compromise between
\# speed and data safety. Itâ€™s up to you to understand if you can relax this to
\# "no" that will will let the operating system flush the output buffer when
\# it wants, for better performances (but if you can live with the idea of
\# some data loss consider the default persistence mode thatâ€™s snapshotting),
\# or on the contrary, use "always" thatâ€™s very slow but a bit safer than
\# everysec.
#
\# If unsure, use "everysec".

\# appendfsync always
appendfsync everysec
\# appendfsync no

################################ VIRTUAL MEMORY ###############################

\# Virtual Memory allows Redis to work with datasets bigger than the actual
\# amount of RAM needed to hold the whole dataset in memory.
\# In order to do so very used keys are taken in memory while the other keys
\# are swapped into a swap file, similarly to what operating systems do
\# with memory pages.
#
\# To enable VM just set â€˜vm-enabledâ€™ to yes, and set the following three
\# VM parameters accordingly to your needs.

vm-enabled no
\# vm-enabled yes

\# This is the path of the Redis swap file. As you can guess, swap files
\# canâ€™t be shared by different Redis instances, so make sure to use a swap
\# file for every redis process you are running. Redis will complain if the
\# swap file is already in use.
#
\# The best kind of storage for the Redis swap file (thatâ€™s accessed at random)
\# is a Solid State Disk (SSD).
#
\# \*\\*\* WARNING \*\** if you are using a shared hosting the default of putting
\# the swap file under /tmp is not secure. Create a dir with access granted
\# only to Redis user and configure Redis to create the swap file there.
vm-swap-file /tmp/redis.swap

\# vm-max-memory configures the VM to use at max the specified amount of
\# RAM. Everything that deos not fit will be swapped on disk \*if\* possible, that
\# is, if there is still enough contiguous space in the swap file.
#
\# With vm-max-memory 0 the system will swap everything it can. Not a good
\# default, just specify the max amount of RAM you can in bytes, but itâ€™s
\# better to leave some margin. For instance specify an amount of RAM
\# thatâ€™s more or less between 60 and 80% of your free RAM.
vm-max-memory 0

\# Redis swap files is split into pages. An object can be saved using multiple
\# contiguous pages, but pages canâ€™t be shared between different objects.
\# So if your page is too big, small objects swapped out on disk will waste
\# a lot of space. If you page is too small, there is less space in the swap
\# file (assuming you configured the same number of total swap file pages).
#
\# If you use a lot of small objects, use a page size of 64 or 32 bytes.
\# If you use a lot of big objects, use a bigger page size.
\# If unsure, use the default ðŸ™‚
vm-page-size 32

\# Number of total memory pages in the swap file.
\# Given that the page table (a bitmap of free/used pages) is taken in memory,
\# every 8 pages on disk will consume 1 byte of RAM.
#
\# The total swap size is vm-page-size * vm-pages
#
\# With the default of 32-bytes memory pages and 134217728 pages Redis will
\# use a 4 GB swap file, that will use 16 MB of RAM for the page table.
#
\# Itâ€™s better to use the smallest acceptable value for your application,
\# but the default is large in order to work in most conditions.
vm-pages 134217728

\# Max number of VM I/O threads running at the same time.
\# This threads are used to read/write data from/to swap file, since they
\# also encode and decode objects from disk to memory or the reverse, a bigger
\# number of threads can help with big objects even if they canâ€™t help with
\# I/O itself as the physical device may not be able to couple with many
\# reads/writes operations at the same time.
#
\# The special value of 0 turn off threaded I/O and enables the blocking
\# Virtual Memory implementation.
vm-max-threads 4

############################### ADVANCED CONFIG ###############################

\# Glue small output buffers together in order to send small replies in a
\# single TCP packet. Uses a bit more CPU but most of the times it is a win
\# in terms of number of queries per second. Use â€˜yesâ€™ if unsure.
glueoutputbuf yes

\# Hashes are encoded in a special way (much more memory efficient) when they
\# have at max a given numer of elements, and the biggest element does not
\# exceed a given threshold. You can configure this limits with the following
\# configuration directives.
hash-max-zipmap-entries 64
hash-max-zipmap-value 512

\# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in
\# order to help rehashing the main Redis hash table (the one mapping top-level
\# keys to values). The hash table implementation redis uses (see dict.c)
\# performs a lazy rehashing: the more operation you run into an hash table
\# that is rhashing, the more rehashing "steps" are performed, so if the
\# server is idle the rehashing is never complete and some more memory is used
\# by the hash table.
#
\# The default is to use this millisecond 10 times every second in order to
\# active rehashing the main dictionaries, freeing memory when possible.
#
\# If unsure:
\# use "activerehashing no" if you have hard latency requirements and it is
\# not a good thing in your environment that Redis can reply form time to time
\# to queries with 2 milliseconds delay.
#
\# use "activerehashing yes" if you donâ€™t have such hard requirements but
\# want to free memory asap when possible.
activerehashing yes

################################## INCLUDES ###################################

\# Include one or more other config files here. This is useful if you
\# have a standard template that goes to all redis server but also need
\# to customize a few per-server settings. Include files can include
\# other files, so use this wisely.
#
\# include /path/to/local.conf
\# include /path/to/other.conf
[/java]